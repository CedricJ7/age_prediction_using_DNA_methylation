# Documentation ComplÃ¨te â€” PrÃ©diction d'Ã‚ge par MÃ©thylation de l'ADN

## Table des MatiÃ¨res

1. [Vue d'Ensemble du Projet](#vue-densemble-du-projet)
2. [Architecture du Code](#architecture-du-code)
3. [Fichiers et leurs RÃ´les](#fichiers-et-leurs-rÃ´les)
4. [Pipeline de DonnÃ©es](#pipeline-de-donnÃ©es)
5. [ModÃ¨les ImplÃ©mentÃ©s](#modÃ¨les-implÃ©mentÃ©s)
6. [MÃ©triques d'Ã‰valuation](#mÃ©triques-dÃ©valuation)
7. [Guide d'Utilisation](#guide-dutilisation)
8. [Pistes d'AmÃ©lioration](#pistes-damÃ©lioration)

---

## Vue d'Ensemble du Projet

### Objectif
DÃ©velopper des **horloges Ã©pigÃ©nÃ©tiques** capables de prÃ©dire l'Ã¢ge chronologique d'un individu Ã  partir de son profil de mÃ©thylation de l'ADN (donnÃ©es EPICv2, ~900,000 sites CpG).

### Concept Biologique
La mÃ©thylation de l'ADN (ajout d'un groupe mÃ©thyle CHâ‚ƒ sur les cytosines des sites CpG) Ã©volue de maniÃ¨re prÃ©visible avec l'Ã¢ge. Cette propriÃ©tÃ© permet de construire des modÃ¨les prÃ©dictifs appelÃ©s "horloges Ã©pigÃ©nÃ©tiques".

### Stack Technique
- **Python 3.10+**
- **Scikit-learn** : ModÃ¨les ML, prÃ©traitement, Ã©valuation
- **XGBoost** : Gradient boosting optimisÃ©
- **Pandas/NumPy** : Manipulation des donnÃ©es
- **Plotly/Dash** : Visualisation interactive
- **SciPy** : Tests statistiques

---

## Architecture du Code

```
age_prediction_using_DNA_methylation/
â”‚
â”œâ”€â”€ Data/                          # DonnÃ©es brutes (non versionnÃ©es)
â”‚   â”œâ”€â”€ annot_projet.csv           # Annotations Ã©chantillons (Ã¢ge, genre, ethnicitÃ©)
â”‚   â”œâ”€â”€ cpg_names_projet.csv       # Liste des noms de CpG
â”‚   â””â”€â”€ c_sample.csv               # Matrice de mÃ©thylation (CpG Ã— Ã©chantillons)
â”‚
â”œâ”€â”€ results/                       # RÃ©sultats gÃ©nÃ©rÃ©s
â”‚   â”œâ”€â”€ metrics.csv                # MÃ©triques de tous les modÃ¨les
â”‚   â”œâ”€â”€ predictions.csv            # PrÃ©dictions sur le test set
â”‚   â”œâ”€â”€ annot_predictions.csv      # Annotations + prÃ©dictions (tous modÃ¨les)
â”‚   â”œâ”€â”€ selected_cpgs.csv          # CpG sÃ©lectionnÃ©s
â”‚   â”œâ”€â”€ coefficients_*.csv         # Coefficients des modÃ¨les linÃ©aires
â”‚   â”œâ”€â”€ report.md                  # Rapport markdown
â”‚   â”œâ”€â”€ rapport_complet.tex        # Rapport LaTeX
â”‚   â”œâ”€â”€ models/                    # ModÃ¨les sauvegardÃ©s (.joblib, .json)
â”‚   â””â”€â”€ plots/                     # Graphiques de diagnostic
â”‚
â”œâ”€â”€ assets/                        # Assets pour l'application web
â”‚   â””â”€â”€ style.css                  # Styles CSS
â”‚
â”œâ”€â”€ train_models.py                # ğŸ”´ PRINCIPAL: Pipeline d'entraÃ®nement
â”œâ”€â”€ app.py                         # Application Dash interactive
â”œâ”€â”€ compare_imputation.py          # Comparaison des mÃ©thodes d'imputation
â”œâ”€â”€ generate_latex_report.py       # GÃ©nÃ©ration de rapport LaTeX
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â””â”€â”€ DOCUMENTATION.md               # Ce fichier
```

---

## Fichiers et leurs RÃ´les

### 1. `train_models.py` â€” Pipeline d'EntraÃ®nement Principal

**Fonction principale**: EntraÃ®ner et Ã©valuer plusieurs modÃ¨les de prÃ©diction d'Ã¢ge.

#### Flux d'exÃ©cution:

```
[1] Chargement des donnÃ©es
    â””â”€â”€ load_annotations() â†’ DataFrame avec Ã¢ge, genre, ethnicitÃ©
    â””â”€â”€ load_cpg_names() â†’ Liste des 900k noms de CpG

[2] PrÃ©paration des features
    â””â”€â”€ select_top_k_cpgs() â†’ SÃ©lection des k CpG les plus corrÃ©lÃ©s avec l'Ã¢ge
    â””â”€â”€ add_demographic_features() â†’ Ajout genre (binaire) + ethnicitÃ© (one-hot)
    â””â”€â”€ Imputation des valeurs manquantes (SimpleImputer, mean)

[3] EntraÃ®nement des modÃ¨les
    â””â”€â”€ build_models() â†’ Liste des modÃ¨les Ã  entraÃ®ner
    â””â”€â”€ optimize_model() â†’ Optimisation des hyperparamÃ¨tres (optionnel)
    â””â”€â”€ model.fit(X_train, y_train)

[4] Ã‰valuation
    â””â”€â”€ evaluate_model() â†’ MAE, MAD, RÂ², CorrÃ©lation, CV scores

[5] Sauvegarde
    â””â”€â”€ metrics.csv, predictions.csv, annot_predictions.csv
    â””â”€â”€ ModÃ¨les (.joblib), Plots, Rapport
```

#### ParamÃ¨tres clÃ©s:

| ParamÃ¨tre | DÃ©faut | Description |
|-----------|--------|-------------|
| `--top-k` | 10000 | Nombre de CpG Ã  sÃ©lectionner |
| `--feature-mode` | topk | Mode: `topk` (corrÃ©lation) ou `pca` |
| `--test-size` | 0.2 | Proportion du test set |
| `--optimize` | False | Activer l'optimisation des hyperparamÃ¨tres |
| `--cv` | 5 | Nombre de folds pour la cross-validation |

#### ModÃ¨les implÃ©mentÃ©s:

```python
models = [
    "ElasticNet",        # RÃ©gression L1+L2
    "Lasso",             # RÃ©gression L1
    "Ridge",             # RÃ©gression L2
    "RandomForest",      # Bagging d'arbres
    "XGBoost",           # Boosting optimisÃ©
    "AltumAge",          # MLP (deep learning)
]
```

---

### 2. `app.py` â€” Application Web Interactive

**Fonction**: Interface Dash pour explorer les rÃ©sultats et comparer les modÃ¨les.

#### Structure de l'interface:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TOPBAR: Logo + Bouton Export LaTeX                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              â”‚  HERO: Titre + Description                       â”‚
â”‚   SIDEBAR    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚              â”‚  TABS:                                           â”‚
â”‚  - Dropdown  â”‚    [Comparaison] [Ã‰chantillons] [Contexte] [RÃ©f] â”‚
â”‚    modÃ¨le    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚              â”‚  CONTENU TAB:                                    â”‚
â”‚  - LÃ©gende   â”‚    - KPIs (CorrÃ©lation, MAE, RÂ², Ã‰cart)         â”‚
â”‚    mÃ©triques â”‚    - Graphiques (barres, scatter, box, histo)   â”‚
â”‚              â”‚    - Analyses stratifiÃ©es (genre, Ã¢ge, batch)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Callbacks principaux:

| Callback | EntrÃ©e | Sortie |
|----------|--------|--------|
| `update_charts` | model-dropdown | Tous les graphiques + KPIs |
| `update_samples_table` | model-dropdown | Tableau des Ã©chantillons |
| `export_report` | btn-export | Fichier LaTeX tÃ©lÃ©chargeable |

#### Graphiques gÃ©nÃ©rÃ©s:

1. **MÃ©triques Cohorte**:
   - MAE par modÃ¨le (barres)
   - RÂ² par modÃ¨le (barres)
   - Scatter tous modÃ¨les
   - RÃ©gression modÃ¨le sÃ©lectionnÃ©

2. **MÃ©triques Individuelles**:
   - Delta Age vs Ã‚ge chronologique
   - Histogramme Age Acceleration
   - Box plot erreurs (tous modÃ¨les)
   - Histogramme Delta Age

3. **Analyses StratifiÃ©es**:
   - Non-linÃ©aritÃ© (erreur vs Ã¢ge + polynÃ´me)
   - DiffÃ©rence par genre (box plot)
   - VariabilitÃ© par batch/chip (box plot)

---

### 3. `compare_imputation.py` â€” Comparaison des MÃ©thodes d'Imputation

**Fonction**: Ã‰valuer l'impact des diffÃ©rentes stratÃ©gies d'imputation sur les performances.

#### MÃ©thodes comparÃ©es:

| MÃ©thode | Description |
|---------|-------------|
| Mean | Remplacement par la moyenne |
| Median | Remplacement par la mÃ©diane |
| Most Frequent | Remplacement par la valeur la plus frÃ©quente |
| KNN (k=5,10,20) | K plus proches voisins |
| Iterative (BayesianRidge) | Imputation itÃ©rative avec rÃ©gression bayÃ©sienne |
| Iterative (ElasticNet) | Imputation itÃ©rative avec ElasticNet |

#### MÃ©triques de comparaison:

- MAE sur le test set
- RÂ² sur le test set
- MAE en cross-validation (5 folds)
- Temps d'imputation

---

### 4. `generate_latex_report.py` â€” GÃ©nÃ©ration de Rapport LaTeX

**Fonction**: CrÃ©er un rapport LaTeX complet avec toutes les analyses.

#### Sections du rapport:

1. **Introduction et Contexte**
   - DÃ©finition mÃ©thylation ADN
   - Concept d'Ã¢ge biologique
   - Horloges Ã©pigÃ©nÃ©tiques
   - Lien avec le cancer

2. **DonnÃ©es et MatÃ©riel**
   - Description de la cohorte
   - Variables disponibles
   - Haute dimensionnalitÃ©
   - DÃ©fis techniques

3. **MÃ©thodologie**
   - Pipeline d'analyse
   - Algorithmes (ElasticNet, RF, XGBoost, MLP)
   - SÃ©lection de variables
   - Gestion des covariables

4. **RÃ©sultats**
   - Tableaux de mÃ©triques
   - Analyse cohorte (corrÃ©lation, MAE)
   - Analyse individuelle (Delta Age, Age Acceleration)

5. **Analyses StratifiÃ©es**
   - Non-linÃ©aritÃ© selon l'Ã¢ge
   - DiffÃ©rences selon le genre
   - VariabilitÃ© technique

6. **Conclusion et Perspectives**

---

## Pipeline de DonnÃ©es

### Flux complet:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ annot_projet.csvâ”‚ â†’ 400 Ã©chantillons avec Ã¢ge, genre, ethnicitÃ©
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ c_sample.csv    â”‚ â†’ Matrice 900k CpG Ã— 400 Ã©chantillons (valeurs Î²: 0-1)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PRÃ‰TRAITEMENT                                                    â”‚
â”‚ 1. Filtrage des CpG avec trop de valeurs manquantes (>5%)       â”‚
â”‚ 2. SÃ©lection top-k CpG par corrÃ©lation avec l'Ã¢ge               â”‚
â”‚ 3. Imputation des valeurs manquantes (KNN, k=5)                  â”‚
â”‚ 4. Ajout features dÃ©mographiques (genre, ethnicitÃ©)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ X: nÃ—p matrice  â”‚ â†’ n=400 Ã©chantillons, p=~10000 features
â”‚ y: vecteur Ã¢ge  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SPLIT TRAIN/TEST (80/20)                                         â”‚
â”‚ X_train: 320Ã—p    X_test: 80Ã—p                                   â”‚
â”‚ y_train: 320      y_test: 80                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ENTRAÃNEMENT                                                     â”‚
â”‚ Pour chaque modÃ¨le:                                              â”‚
â”‚   1. (Optionnel) Optimisation hyperparamÃ¨tres (RandomizedSearchCV)â”‚
â”‚   2. Fit sur X_train, y_train                                    â”‚
â”‚   3. PrÃ©diction sur X_test                                       â”‚
â”‚   4. Calcul mÃ©triques (MAE, RÂ², CorrÃ©lation)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RÃ‰SULTATS       â”‚ â†’ metrics.csv, predictions.csv, modÃ¨les sauvegardÃ©s
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ModÃ¨les ImplÃ©mentÃ©s

### 1. ElasticNet (RÃ©gression LinÃ©aire RÃ©gularisÃ©e)

```python
# Combinaison L1 (Lasso) + L2 (Ridge)
# Objectif: min ||y - XÎ²||Â² + Î±(Ï||Î²||â‚ + (1-Ï)||Î²||Â²/2)

ElasticNet(
    alpha=0.1,      # Force de rÃ©gularisation
    l1_ratio=0.5,   # Balance L1/L2 (0.5 = Ã©quilibre)
    max_iter=50000, # ItÃ©rations max
)
```

**Avantages**: SÃ©lection de variables, interprÃ©tabilitÃ©, gÃ¨re la multicolinÃ©aritÃ©
**InconvÃ©nients**: Suppose une relation linÃ©aire

### 2. Random Forest (Bagging)

```python
# Ensemble d'arbres entraÃ®nÃ©s sur des bootstrap samples
RandomForestRegressor(
    n_estimators=300,      # Nombre d'arbres
    max_depth=20,          # Profondeur max
    min_samples_split=5,   # Min Ã©chantillons pour split
    max_features="sqrt",   # Features par arbre: âˆšp
)
```

**Avantages**: Robuste, gÃ¨re les non-linÃ©aritÃ©s, peu d'hyperparamÃ¨tres
**InconvÃ©nients**: Moins interprÃ©table, peut overfitter

### 3. XGBoost

```python
# Boosting: arbres entraÃ®nÃ©s sÃ©quentiellement sur les rÃ©sidus
XGBRegressor(
    n_estimators=400,       # Nombre d'itÃ©rations
    learning_rate=0.05,     # Taux d'apprentissage
    max_depth=6,            # Profondeur des arbres
    subsample=0.8,          # Fraction d'Ã©chantillons par arbre
    colsample_bytree=0.8,   # Fraction de features par arbre
    reg_alpha=0.1,          # RÃ©gularisation L1
    reg_lambda=2.0,         # RÃ©gularisation L2
)
```

**Avantages**: Excellentes performances, rÃ©gularisation intÃ©grÃ©e
**InconvÃ©nients**: Risque d'overfitting, plus lent Ã  entraÃ®ner

### 4. AltumAge (MLP)

```python
# RÃ©seau de neurones multicouche
MLPRegressor(
    hidden_layer_sizes=(64, 64, 32),  # Architecture
    activation="relu",                 # Fonction d'activation
    alpha=0.001,                       # RÃ©gularisation L2
    early_stopping=True,               # ArrÃªt prÃ©coce
)
```

**Avantages**: Peut capturer des relations complexes
**InconvÃ©nients**: NÃ©cessite plus de donnÃ©es, moins interprÃ©table

---

## MÃ©triques d'Ã‰valuation

### MÃ©triques de Performance

| MÃ©trique | Formule | InterprÃ©tation |
|----------|---------|----------------|
| **MAE** | mean(\|y - Å·\|) | Erreur moyenne en annÃ©es |
| **MAD** | median(\|y - Å·\|) | Erreur mÃ©diane (robuste aux outliers) |
| **RMSE** | âˆšmean((y - Å·)Â²) | Erreur quadratique (pÃ©nalise les gros Ã©carts) |
| **RÂ²** | 1 - SS_res/SS_tot | Variance expliquÃ©e (0-1) |
| **CorrÃ©lation** | corr(y, Å·) | Force de la relation linÃ©aire |

### MÃ©triques Biologiques

| MÃ©trique | Formule | InterprÃ©tation |
|----------|---------|----------------|
| **Delta Age** | Å· - y | DiffÃ©rence Ã¢ge prÃ©dit - chronologique |
| **Age Acceleration** | rÃ©sidu(Å· ~ y) | Vieillissement relatif Ã  la population |
| **Ã‰cart moyen** | mean(Å· - y) | Biais systÃ©matique du modÃ¨le |

### MÃ©triques de Validation

| MÃ©trique | Description |
|----------|-------------|
| **CV MAE** | MAE moyenne sur k-folds |
| **CV std** | Ã‰cart-type du MAE sur k-folds |
| **Overfitting ratio** | MAE_test / MAE_train (idÃ©al â‰ˆ 1) |

---

## Guide d'Utilisation

### Installation

```bash
# Cloner le projet
git clone <repo_url>
cd age_prediction_using_DNA_methylation

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### EntraÃ®nement des modÃ¨les

```bash
# EntraÃ®nement standard
python train_models.py --top-k 10000

# Avec optimisation des hyperparamÃ¨tres
python train_models.py --top-k 10000 --optimize --n-iter 30

# Avec PCA au lieu de top-k
python train_models.py --feature-mode pca --pca-components 400
```

### Comparaison des imputations

```bash
python compare_imputation.py --top-k 5000
```

### GÃ©nÃ©ration du rapport LaTeX

```bash
python generate_latex_report.py

# Compiler le PDF
cd results
pdflatex rapport_complet.tex
pdflatex rapport_complet.tex  # 2Ã¨me passe pour table des matiÃ¨res
```

### Lancer l'application web

```bash
python app.py
# Ouvrir http://127.0.0.1:8050 dans un navigateur
```

---

## Pistes d'AmÃ©lioration

### 1. AmÃ©lioration des DonnÃ©es

- [ ] **Normalisation des batch effects**: Appliquer ComBat ou SVA pour corriger la variabilitÃ© technique entre chips
- [ ] **Augmentation de donnÃ©es**: Si possible, inclure plus d'Ã©chantillons
- [ ] **Filtrage avancÃ©**: Utiliser des critÃ¨res biologiques pour la sÃ©lection des CpG (ex: CpG dans des promoteurs)

### 2. AmÃ©lioration des Features

- [ ] **SÃ©lection de features avancÃ©e**: 
  - Recursive Feature Elimination (RFE)
  - Boruta algorithm
  - SHAP-based selection
- [ ] **Features dÃ©rivÃ©es**: 
  - AgrÃ©gations par Ã®lots CpG
  - Scores de voies biologiques
- [ ] **Embeddings**: 
  - Autoencoders pour rÃ©duction de dimensionnalitÃ©
  - Word2Vec sur sÃ©quences CpG

### 3. AmÃ©lioration des ModÃ¨les

- [ ] **Architectures deep learning**:
  - Convolutional Neural Networks (CNN) sur les rÃ©gions gÃ©nomiques
  - Attention mechanisms
  - Transformers adaptÃ©s aux donnÃ©es omiques
- [ ] **Ensemble avancÃ©s**:
  - Stacking avec mÃ©ta-learner
  - Voting avec poids optimisÃ©s
- [ ] **ModÃ¨les spÃ©cifiques**:
  - ModÃ¨les sÃ©parÃ©s par genre
  - ModÃ¨les par tranche d'Ã¢ge

### 4. AmÃ©lioration de l'Ã‰valuation

- [ ] **Validation externe**: Tester sur des cohortes indÃ©pendantes
- [ ] **Calibration**: VÃ©rifier et corriger la calibration des prÃ©dictions
- [ ] **Intervalles de confiance**: Bootstrap pour estimer l'incertitude

### 5. AmÃ©lioration de l'Application

- [ ] **Export PDF natif**: IntÃ©grer ReportLab ou WeasyPrint
- [ ] **Comparaison interactive**: Permettre de comparer 2 modÃ¨les cÃ´te Ã  cÃ´te
- [ ] **Upload de donnÃ©es**: Permettre de charger de nouvelles donnÃ©es

### 6. Optimisation du Code

- [ ] **ParallÃ©lisation**: Utiliser Dask pour le traitement des gros fichiers
- [ ] **Caching**: Mettre en cache les features prÃ©-calculÃ©es
- [ ] **GPU**: Utiliser RAPIDS pour accÃ©lÃ©rer le preprocessing

---

## RÃ©fÃ©rences

1. Horvath, S. (2013). DNA methylation age of human tissues. *Genome Biology*, 14(10), R115.
2. Hannum, G., et al. (2013). Genome-wide methylation profiles. *Molecular Cell*, 49(2), 359-367.
3. Levine, M. E., et al. (2018). PhenoAge biomarker. *Aging*, 10(4), 573-591.
4. Lu, A. T., et al. (2019). GrimAge predictor. *Aging*, 11(2), 303-327.
5. de Lima Camillo, L. P., et al. (2021). AltumAge. *Aging and Disease*.

---

*Documentation gÃ©nÃ©rÃ©e automatiquement â€” DNAm Age Prediction Benchmark*
